# Expanded Description: Pong with Physics-Based Flippers and RL Training

This project will create a modified version of the classic Pong game where the paddles behave like pinball flippers rather than the traditional rigid paddles. The flippers will be able to:

1. Move vertically along the edges of the screen (like traditional Pong)
2. Rotate/swing toward the ball to hit it at different angles and speeds
3. Influence the ball's trajectory and velocity based on the swing mechanics

Two reinforcement learning (RL) agents will train against each other in this environment, learning optimal strategies for both vertical positioning and swing timing. The game will use physics-based interactions for realistic ball and flipper mechanics.

To visualize the training progress, every 5th game will be rendered to the screen using Pygame. No sound effects or documentation will be included.

Key design decisions:
- We'll use the PPO (Proximal Policy Optimization) algorithm for the RL agents due to its stability and performance
- The observation space will include ball position, ball velocity, flipper positions, and flipper angles
- The action space will include vertical movement and flipper swing control
- Rewards will be based on successful ball returns and scoring points
- The physics engine will be simplified but will model basic momentum and collision effects
- Training will happen in an accelerated mode when not rendering

## File Tree

1. **main.py**
   - Purpose: Entry point for the application, initializes the game, RL environment, and training loop
   - Import: Not imported by other files (is the starting point)

2. **game/pong_env.py**
   - Purpose: Defines the PongEnv class that implements the game environment and RL interface
   - Import: `from game.pong_env import PongEnv`

3. **game/physics.py**
   - Purpose: Contains physics utilities for ball movement, collision detection, and flipper mechanics
   - Import: `from game.physics import PhysicsEngine, Collision`

4. **game/objects.py**
   - Purpose: Defines game objects (Ball, Flipper) with their properties and behaviors
   - Import: `from game.objects import Ball, Flipper`

5. **game/renderer.py**
   - Purpose: Handles visualization of the game state using Pygame
   - Import: `from game.renderer import GameRenderer`

6. **rl/agents.py**
   - Purpose: Implements the RL agent class and training algorithms (PPO)
   - Import: `from rl.agents import Agent, PPOAgent`

7. **rl/models.py**
   - Purpose: Neural network architectures for the RL policy and value functions
   - Import: `from rl.models import PolicyNetwork, ValueNetwork`

8. **rl/memory.py**
   - Purpose: Experience replay buffer and trajectory storage for training
   - Import: `from rl.memory import ReplayBuffer, Trajectory`

9. **rl/trainer.py**
   - Purpose: Manages the training process, including episode collection and model updates
   - Import: `from rl.trainer import RLTrainer`

10. **utils/config.py**
    - Purpose: Contains configuration parameters for the game, physics, and RL algorithms
    - Import: `from utils.config import GameConfig, TrainingConfig`

11. **utils/helpers.py**
    - Purpose: Utility functions for data processing, logging, and other helper tasks
    - Import: `from utils.helpers import preprocess_observation, calculate_rewards`Start testing as soon as possible. DO NOT start making fixes or improvements until you have tested to see if it is working as is.  Your project directory is /home/myuser/apps/pinpong. You need to make sure that all files you create and work you do is done in that directory.
