<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
__init__.py
agent_display_console.py
command_converter.py
context_helpers.py
file_logger.py
llm_client.py
miniOR.py
output_manager.py
web_ui.py
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="__init__.py">
"""Utility functions and classes used throughout Slaze."""

__all__ = []
</file>

<file path="agent_display_console.py">
import asyncio
import json
import os
import sys
from rich.console import Console
from rich.panel import Panel
from rich.prompt import Prompt, Confirm, IntPrompt
from rich.syntax import Syntax
from pathlib import Path
from config import (
    PROMPTS_DIR,
    get_constant,
    set_constant,
    set_prompt_name,
    write_constants_to_file,
)

class AgentDisplayConsole:
    def __init__(self):
        # Configure console for Windows Unicode support
        if os.name == 'nt':  # Windows
            # Set environment variables for UTF-8 support
            os.environ['PYTHONIOENCODING'] = 'utf-8'
            # Try to set Windows console to UTF-8 mode
            try:
                # Enable UTF-8 mode on Windows
                os.system('chcp 65001 > nul')
                # Reconfigure stdout/stderr for UTF-8 (Python 3.7+)
                if hasattr(sys.stdout, 'reconfigure') and callable(getattr(sys.stdout, 'reconfigure', None)):
                    sys.stdout.reconfigure(encoding='utf-8', errors='replace')
                if hasattr(sys.stderr, 'reconfigure') and callable(getattr(sys.stderr, 'reconfigure', None)):
                    sys.stderr.reconfigure(encoding='utf-8', errors='replace')
            except Exception:
                pass
        
        # Initialize Rich console with safe settings for Windows
        self.console = Console(
            force_terminal=True,
            legacy_windows=False,
            file=sys.stdout,
            width=120,
            safe_box=True,
            highlight=False
        )

    def add_message(self, msg_type, content):
        # Use safer characters for Windows compatibility
        if msg_type == "user":
            self.console.print(f"[User]: {content}")
        elif msg_type == "assistant":
            self.console.print(f"[Assistant]: {content}")
        elif msg_type == "tool":
            self.console.print(f"[Tool]: {content}")
        else:
            self.console.print(f"[{msg_type}]: {content}")

    async def wait_for_user_input(self, prompt_message=">> Your input: "):
        return await asyncio.to_thread(input, prompt_message)

    async def select_prompt_console(self):
        self.console.print("--- Select a Prompt ---")
        if not PROMPTS_DIR.exists():
            self.console.print(f"[bold yellow]Warning: Prompts directory '{PROMPTS_DIR}' not found. Creating it now.[/bold yellow]")
            try:
                PROMPTS_DIR.mkdir(parents=True, exist_ok=True)
                self.console.print(f"[green]Successfully created prompts directory: {PROMPTS_DIR}[/green]")
            except Exception as e:
                self.console.print(f"[bold red]Error creating prompts directory {PROMPTS_DIR}: {e}[/bold red]")
                return "Default task due to directory creation error."

        options = {}
        prompt_files = sorted([f for f in PROMPTS_DIR.iterdir() if f.is_file() and f.suffix == '.md'])

        prompt_lines = []
        for i, prompt_file in enumerate(prompt_files):
            options[str(i + 1)] = prompt_file
            prompt_lines.append(f"{i + 1}. {prompt_file.name}")
        
        if prompt_lines:
            self.console.print("\n".join(prompt_lines))

        create_new_option_num = len(options) + 1
        self.console.print(f"{create_new_option_num}. Create a new prompt")

        choice = IntPrompt.ask("Enter your choice", choices=[str(i) for i in range(1, create_new_option_num + 1)])

        if choice != create_new_option_num:
            prompt_path = options[str(choice)]
            task = prompt_path.read_text(encoding="utf-8")
            prompt_name = prompt_path.stem
            self.console.print(
                Panel(
                    Syntax(task, "markdown", theme="dracula", line_numbers=True),
                    title="Current Prompt Content",
                )
            )
            if Confirm.ask(f"Do you want to edit '{prompt_path.name}'?", default=False):
                new_lines = []
                while True:
                    try:
                        line = await self.wait_for_user_input("")
                        new_lines.append(line)
                    except EOFError:
                        break
                if new_lines:
                    task = "\n".join(new_lines)
                    prompt_path.write_text(task, encoding="utf-8")
        else:
            new_filename_input = Prompt.ask("Enter a filename for the new prompt", default="custom_prompt")
            filename_stem = new_filename_input.strip().replace(" ", "_").replace(".md", "")
            prompt_name = filename_stem
            new_prompt_path = PROMPTS_DIR / f"{filename_stem}.md"
            new_prompt_lines = []
            while True:
                try:
                    line = await self.wait_for_user_input("")
                    new_prompt_lines.append(line)
                except EOFError:
                    break
            if new_prompt_lines:
                task = "\n".join(new_prompt_lines)
                new_prompt_path.write_text(task, encoding="utf-8")
            else:
                task = ""

        # Configure repository directory for this prompt
        base_repo_dir = Path(get_constant("TOP_LEVEL_DIR")) / "repo"
        repo_dir = base_repo_dir / prompt_name
        repo_dir.mkdir(parents=True, exist_ok=True)
        set_prompt_name(prompt_name)
        set_constant("REPO_DIR", repo_dir)
        write_constants_to_file()

        return task

    async def confirm_tool_call(self, tool_name: str, args: dict, schema: dict) -> dict | None:
        """Display tool call parameters and allow the user to edit them."""
        self.console.print(Panel(f"Tool call: [bold]{tool_name}[/bold]", title="Confirm Tool"))
        updated_args = dict(args)
        properties = schema.get("properties", {}) if schema else {}

        for param in properties:
            current_val = args.get(param, "")
            default_str = str(current_val) if current_val is not None else ""
            user_val = Prompt.ask(param, default=default_str)
            if user_val != default_str:
                pinfo = properties.get(param, {})
                if pinfo.get("type") == "integer":
                    try:
                        updated_args[param] = int(user_val)
                    except ValueError:
                        updated_args[param] = user_val
                elif pinfo.get("type") == "array":
                    try:
                        updated_args[param] = json.loads(user_val)
                    except Exception:
                        updated_args[param] = [v.strip() for v in user_val.split(',') if v.strip()]
                else:
                    updated_args[param] = user_val

        if Confirm.ask("Execute tool with these parameters?", default=True):
            return updated_args
        return None
</file>

<file path="command_converter.py">
import logging
import platform
import os
import re
from typing import Optional, Dict, Any
from pathlib import Path
from config import get_constant
from .llm_client import create_llm_client

logger = logging.getLogger(__name__)

class CommandConverter:
    """
    LLM-based command converter that transforms bash commands to be appropriate
    for the current system environment.
    """
    
    def __init__(self):
        self.system_info = self._get_system_info()
        self.conversion_prompt = self._build_conversion_prompt()
    
    def _get_system_info(self) -> Dict[str, Any]:
        """Gather system information for command conversion context."""
        return {
            "os_name": platform.system(),
            "os_version": platform.version(),
            "architecture": platform.machine(),
            "python_version": platform.python_version(),
            "shell": os.environ.get("SHELL", "/bin/bash"),
            "home_dir": str(Path.home()),
            "current_working_dir": str(Path.cwd()),
            "path_separator": os.pathsep,
            "file_separator": os.sep,
            "environment_vars": {
                "PATH": os.environ.get("PATH", ""),
                "USER": os.environ.get("USER", ""),
                "HOME": os.environ.get("HOME", ""),
            }
        }
    
    def _build_conversion_prompt(self) -> str:
        """Build the system prompt for command conversion."""
        os_name = self.system_info['os_name']
        
        # Build OS-specific examples and rules
        if os_name == "Windows":
            examples = """EXAMPLES:
Input: "dir"
Output: dir

Input: "dir C:\\path"
Output: dir C:\\path

Input: "find /path -type f"
Output: dir /s /b C:\\path\\* | findstr /v "\\\\\\."

Input: "ls -la"
Output: dir

Input: "echo hello"
Output: echo hello"""
            
            rules = f"""RULES:
- Keep Windows commands (dir, type, copy, etc.) as-is - do NOT convert to Linux equivalents
- If a Linux command is used, convert it to the Windows equivalent
- For file listing: use "dir" not "ls"
- For finding files: use "dir /s /b" not "find"
- Use Windows path separators (\\) when needed
- Hidden files on Windows start with . - filter them when appropriate
- Ensure the command will work on {os_name}
- Return ONLY the command, no other text"""
        else:
            examples = """EXAMPLES:
Input: "find /path -type f"
Output: find /path -type f -not -path "*/.*"

Input: "ls -la /directory"  
Output: ls -la /directory | grep -v "^\\."

Input: "dir"
Output: ls

Input: "echo hello"
Output: echo hello"""
            
            rules = f"""RULES:
- Keep Linux/Unix commands as-is when they work correctly
- If a Windows command is used, convert it to the Linux equivalent  
- For file listing: use "ls" not "dir"
- Always exclude hidden files/directories in find and ls operations
- Use Linux path separators (/) when needed
- Ensure the command will work on {os_name}
- Return ONLY the command, no other text"""
        
        return f"""You are a command converter that adapts commands for different system environments.

SYSTEM INFORMATION:
- OS: {os_name} {self.system_info['os_version']}
- Architecture: {self.system_info['architecture']}
- Shell: {self.system_info['shell']}
- Working Directory: {self.system_info['current_working_dir']}
- Path Separator: {self.system_info['path_separator']}
- File Separator: {self.system_info['file_separator']}

CONVERSION GOALS:
1. Ensure commands work properly on the current system ({os_name})
2. Filter out hidden files/directories when listing or finding files
3. Convert between Windows and Linux command equivalents as needed
4. Use appropriate flags and options for the target system
5. Handle cross-platform compatibility issues

CRITICAL OUTPUT FORMAT:
You MUST respond with ONLY the converted command, nothing else. No explanations, no markdown, no additional text.
The response should be a single line containing only the executable command.

{examples}

{rules}
"""

    async def convert_command(self, original_command: str) -> str:
        """
        Convert a command using LLM to be appropriate for the current system.
        
        Args:
            original_command: The original bash command to convert
            
        Returns:
            The converted command appropriate for the current system
        """
        try:
            # Get the model from config
            model = get_constant("MAIN_MODEL", "anthropic/claude-sonnet-4")
            
            # Prepare the conversion request
            converted_command = await self._call_llm(model, original_command)
            
            # Validate and clean the response
            cleaned_command = self._clean_response(converted_command)
            
            logger.info(f"Command converted: '{original_command}' -> '{cleaned_command}'")
            return cleaned_command
            
        except Exception as e:
            logger.warning(f"Command conversion failed for '{original_command}': {e}")
            # Fallback to original command if conversion fails
            return original_command
    
    async def _call_llm(self, model: str, command: str) -> str:
        """
        Call the LLM API to convert the command.
        
        Args:
            model: The model to use for conversion
            command: The original command
            
        Returns:
            The LLM response containing the converted command
        """
        # Prepare the messages for the LLM
        messages = [
            {
                "role": "system", 
                "content": self.conversion_prompt
            },
            {
                "role": "user", 
                "content": command
            }
        ]
        
        # Create LLM client and call it
        client = create_llm_client(model)
        return await client.call(
            messages=messages,
            max_tokens=200,  # Keep response short
            temperature=0.1  # Low temperature for consistent output
        )
    
    def _clean_response(self, response: str) -> str:
        """
        Clean the LLM response to extract just the command.
        
        Args:
            response: The raw LLM response
            
        Returns:
            The cleaned command string
        """
        # Remove any markdown code blocks
        response = re.sub(r'^```.*?\n|```$', '', response, flags=re.MULTILINE)
        
        # Remove leading/trailing whitespace
        response = response.strip()
        
        # Split by lines and take the first non-empty line
        lines = [line.strip() for line in response.split('\n') if line.strip()]
        if not lines:
            raise ValueError("Empty response from LLM")
        
        command = lines[0]
        
        # Basic validation - ensure it looks like a command
        if not command or len(command) > 1000:  # Reasonable length limit
            raise ValueError(f"Invalid command format: {command}")
        
        return command

# Global instance for reuse
_converter_instance: Optional[CommandConverter] = None

async def convert_command_for_system(original_command: str) -> str:
    """
    Convert a bash command to be appropriate for the current system.
    
    Args:
        original_command: The original bash command
        
    Returns:
        The converted command appropriate for the current system
    """
    global _converter_instance
    
    if _converter_instance is None:
        _converter_instance = CommandConverter()
    
    return await _converter_instance.convert_command(original_command)
</file>

<file path="context_helpers.py">
from typing import Any, Dict, List, Union
from pathlib import Path
from datetime import datetime

import os
from utils.web_ui import WebUI
from utils.agent_display_console import AgentDisplayConsole
# from config import write_to_file # Removed as it was for ic
# Removed: from load_constants import *
from config import MAIN_MODEL, get_constant, googlepro # Import get_constant
from utils.file_logger import aggregate_file_states
from openai import OpenAI
import logging
import json
from tenacity import retry, stop_after_attempt, wait_random_exponential
# from icecream import ic # Removed
# from rich import print as rr # Removed

# ic.configureOutput(includeContext=True, outputFunction=write_to_file) # Removed

logger = logging.getLogger(__name__)

QUICK_SUMMARIES = []


def format_messages_to_restart(messages):
    """
    Format a list of messages into a formatted string.
    """
    try:
        output_pieces = []
        for msg in messages:
            output_pieces.append(f"\n{msg['role'].upper()}:")
            if isinstance(msg["content"], list):
                for content_block in msg["content"]:
                    if isinstance(content_block, dict):
                        if content_block.get("type") == "tool_result":
                            output_pieces.append("\nResult:")
                            for item in content_block.get("content", []):
                                if item.get("type") == "text":
                                    output_pieces.append(f"\n{item.get('text')}")
                        else:
                            for key, value in content_block.items():
                                output_pieces.append(f"\n{value}")
                    else:
                        output_pieces.append(f"\n{content_block}")
            else:
                output_pieces.append(f"\n{msg['content']}")
            output_pieces.append("\n" + "-" * 80)
        return "".join(output_pieces)
    except Exception as e:
        return f"Error during formatting: {str(e)}"


def format_messages_to_string(messages):
    """Return a human readable string for a list of messages."""

    def _val(obj, key, default=None):
        if isinstance(obj, dict):
            return obj.get(key, default)
        return getattr(obj, key, default)

    try:
        output_pieces = []
        for msg in messages:
            role = msg.get("role", "unknown").upper()
            output_pieces.append(f"\n{role}:")

            if "tool_call_id" in msg:
                output_pieces.append(f"\nTool Call ID: {msg['tool_call_id']}")

            if msg.get("tool_calls"):
                for tc in msg["tool_calls"]:
                    name = _val(_val(tc, "function"), "name")
                    args = _val(_val(tc, "function"), "arguments")
                    tc_id = _val(tc, "id")
                    output_pieces.append(
                        f"\nTool Call -> {name or 'unknown'} (ID: {tc_id or 'n/a'})"
                    )
                    if args:
                        try:
                            parsed = json.loads(args) if isinstance(args, str) else args
                            formatted = json.dumps(parsed, indent=2)
                        except Exception:
                            formatted = str(args)
                        output_pieces.append(f"\nArguments: {formatted}")

            content = msg.get("content")
            if isinstance(content, list):
                for block in content:
                    if isinstance(block, dict):
                        btype = block.get("type")
                        if btype == "text":
                            output_pieces.append(f"\n{block.get('text', '')}")
                        elif btype == "image":
                            output_pieces.append("\n[Image content omitted]")
                        elif btype == "tool_use":
                            output_pieces.append(f"\nTool Call: {block.get('name')}")
                            if "input" in block:
                                inp = block["input"]
                                if isinstance(inp, (dict, list)):
                                    output_pieces.append(
                                        f"\nInput: {json.dumps(inp, indent=2)}"
                                    )
                                else:
                                    output_pieces.append(f"\nInput: {inp}")
                        elif btype == "tool_result":
                            output_pieces.append(
                                f"\nTool Result [ID: {block.get('tool_use_id', 'unknown')}]"
                            )
                            if block.get("is_error"):
                                output_pieces.append("\nError: True")
                            for item in block.get("content", []):
                                if item.get("type") == "text":
                                    output_pieces.append(f"\n{item.get('text', '')}")
                                elif item.get("type") == "image":
                                    output_pieces.append("\n[Image content omitted]")
                        else:
                            for key, value in block.items():
                                if key == "cache_control":
                                    continue
                                output_pieces.append(f"\n{key}: {value}")
                    else:
                        output_pieces.append(f"\n{block}")
            elif content is not None:
                output_pieces.append(f"\n{content}")

            output_pieces.append("\n" + "-" * 80)

        return "".join(output_pieces)
    except Exception as e:
        return f"Error during formatting: {str(e)}"


async def summarize_recent_messages(
    short_messages: List[Dict[str, Any]], display: Union[WebUI, AgentDisplayConsole]
) -> str:
    """
    Summarize the most recent messages.
    """
    
    try:
        OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
        sum_client = OpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=OPENROUTER_API_KEY,
        )
        all_summaries = get_all_summaries()
        model = MAIN_MODEL
        conversation_text = ""
        for msg in short_messages:
            role = msg["role"].upper()
            if isinstance(msg["content"], list):
                for block in msg["content"]:
                    if isinstance(block, dict):
                        if block.get("type") == "text":
                            content = block.get("text", "")
                            if len(content) > 150000:
                                content = (
                                    content[:70000]
                                    + " ... [TRUNCATED] ... "
                                    + content[-70000:]
                                )
                            conversation_text += f"\n{role}: {content}"
                        elif block.get("type") == "tool_result":
                            for item in block.get("content", []):
                                if item.get("type") == "text":
                                    content = item.get("text", "")
                                    if len(content) > 150000:
                                        content = (
                                            content[:70000]
                                            + " ... [TRUNCATED] ... "
                                            + content[-70000:]
                                        )
                                    conversation_text += (
                                        f"\n{role} (Tool Result): {content}"
                                    )
            else:
                content = msg["content"]
                if len(content) > 150000:
                    content = (
                        content[:70000] + " ... [TRUNCATED] ... " + content[-70000:]
                    )
                conversation_text += f"\n{role}: {content}"
        logger.debug(f"conversation_text for summary: {conversation_text[:500]}...") # Log snippet
        summary_prompt = f"""Please provide your response in a concise markdown format with short statements that document what happened. Structure your response as a list with clear labels for each step, such as:

            - **Action:** [brief description of what was done]
            - **Result:** [outcome of the action]

            
            - Here are the actions that have been logged so far.  You should not repeat these, they are only to give you context to what is going on. 
            Previous Actions:
            {all_summaries}
            Please be specific but concise, focusing on documenting the sequence of events in this structured format.
            Messages to summarize:
            {conversation_text}"""
        response = sum_client.chat.completions.create(
            model=model, messages=[{"role": "user", "content": summary_prompt}],
            max_tokens=get_constant("MAX_SUMMARY_TOKENS", 4000) # Use get_constant
        )
        logger.debug(f"Summary API response: {response}")

        # Add error handling for response
        if not response or not response.choices or len(response.choices) == 0:
            error_msg = "Error: No valid response received from summary API"
            # print(response) # Replaced by logger
            logger.error(f"{error_msg} - Full response: {response}")
            return "Error generating summary: No valid response received from API"

        summary = response.choices[0].message.content

        # Check if summary is None or empty
        if not summary:
            error_msg = "Error: Empty summary received from API"
            logger.error(error_msg)
            return "Error generating summary: Empty summary received from API"

        logger.debug(f"Generated summary: {summary[:500]}...") # Log snippet
        return summary
    except Exception as e:
        error_msg = f"Error generating summary: {str(e)}"
        logger.error(error_msg, exc_info=True)
        return error_msg


def filter_messages(messages: List[Dict]) -> List[Dict]:
    """
    Keep only messages with role 'user' or 'assistant'.
    Also keep any tool_result messages that contain errors.
    """
    keep_roles = {"user", "assistant"}
    filtered = []
    for msg in messages:
        if msg.get("role") in keep_roles:
            filtered.append(msg)
        elif isinstance(msg.get("content"), list):
            for block in msg["content"]:
                if isinstance(block, dict) and block.get("type") == "tool_result":
                    # Check if any text in the tool result indicates an error
                    text = ""
                    for item in block.get("content", []):
                        if isinstance(item, dict) and item.get("type") == "text":
                            text += item.get("text", "")
                    if "error" in text.lower():
                        filtered.append(msg)
                        break
    return filtered


def extract_text_from_content(content: Any) -> str:
    if isinstance(content, str):
        return content
    elif isinstance(content, list):
        text_parts = []
        for item in content:
            if isinstance(item, dict):
                if item.get("type") == "text":
                    text_parts.append(item.get("text", ""))
                elif item.get("type") == "tool_result":
                    for sub_item in item.get("content", []):
                        if sub_item.get("type") == "text":
                            text_parts.append(sub_item.get("text", ""))
        return " ".join(text_parts)
    return ""


def truncate_message_content(content: Any, max_length: int = 150_000) -> Any:
    if isinstance(content, str):
        if len(content) > max_length:
            return content[:70000] + " ... [TRUNCATED] ... " + content[-70000:]
        return content
    elif isinstance(content, list):
        return [truncate_message_content(item, max_length) for item in content]
    elif isinstance(content, dict):
        return {
            k: truncate_message_content(v, max_length) if k != "source" else v
            for k, v in content.items()
        }
    return content


def add_summary(summary: str) -> None:
    """Add a new summary to the global list with timestamp and log it to a file."""
    stripped_summary = summary.strip()
    QUICK_SUMMARIES.append(stripped_summary)

    try:
        summary_file_path = Path(get_constant("SUMMARY_FILE"))
        summary_file_path.parent.mkdir(parents=True, exist_ok=True)

        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_entry = f"\n--------------------\n[{timestamp}]\n{stripped_summary}\n--------------------\n"

        with open(summary_file_path, "a", encoding="utf-8") as f:
            f.write(log_entry)
    except Exception as e:
        logger.error(f"Failed to log summary to file: {e}", exc_info=True)


def get_all_summaries() -> str:
    """Combine all summaries into a chronological narrative."""
    if not QUICK_SUMMARIES:
        return "No summaries available yet."

    combined = "\n"
    for entry in QUICK_SUMMARIES:
        combined += f"{entry}\n"
    return combined


async def reorganize_context(messages: List[Dict[str, Any]], summary: str) -> str:
    """Reorganize the context by filtering and summarizing messages."""
    conversation_text = ""

    # Look for tool results related to image generation
    image_generation_results = []

    for msg in messages:
        role = msg["role"].upper()
        if isinstance(msg["content"], list):
            for block in msg["content"]:
                if isinstance(block, dict):
                    if block.get("type") == "text":
                        conversation_text += f"\n{role}: {block.get('text', '')}"
                    elif block.get("type") == "tool_result":
                        # Track image generation results
                        if any(
                            "picture_generation" in str(item)
                            for item in block.get("content", [])
                        ):
                            for item in block.get("content", []):
                                if item.get(
                                    "type"
                                ) == "text" and "Generated image" in item.get(
                                    "text", ""
                                ):
                                    image_generation_results.append(
                                        item.get("text", "")
                                    )

                        for item in block.get("content", []):
                            if item.get("type") == "text":
                                conversation_text += (
                                    f"\n{role} (Tool Result): {item.get('text', '')}"
                                )
        else:
            conversation_text += f"\n{role}: {msg['content']}"

    # Add special section for image generation if we found any
    if image_generation_results:
        conversation_text += "\n\nIMAGE GENERATION RESULTS:\n" + "\n".join(
            image_generation_results
        )
    logger.debug(f"Conversation text for reorganize_context: {conversation_text[:500]}...") # Log snippet
    summary_prompt = f"""I need a summary of completed steps and next steps for a project that is ALREADY IN PROGRESS. 
    This is NOT a new project - you are continuing work on an existing codebase.

    VERY IMPORTANT INSTRUCTIONS:
    1. ALL FILES mentioned as completed or created ARE ALREADY CREATED AND FULLY FUNCTIONAL.
       - Do NOT suggest recreating these files.
       - Do NOT suggest checking if these files exist.
       - Assume all files mentioned in completed steps exist exactly where they are described.
    
    2. ALL STEPS listed as completed HAVE ALREADY BEEN SUCCESSFULLY DONE.
       - Do NOT suggest redoing any completed steps.
    
    3. Your summary should be in TWO clearly separated parts:
       a. COMPLETED: List all tasks/steps that have been completed so far
       b. NEXT STEPS: List 1-4 specific, actionable steps that should be taken next to complete the project
    
    4. List each completed item and next step ONLY ONCE, even if it appears multiple times in the context.
    
    5. If any images were generated, mention each image, its purpose, and its location in the COMPLETED section.
    
    Please format your response with:
    <COMPLETED>
    [List of ALL completed steps and created files - these are DONE and exist]
    </COMPLETED>

    <NEXT_STEPS>
    [Numbered list of 1-4 next steps to complete the project]
    </NEXT_STEPS>

    Here is the Summary part:
    {summary}
    
    Here is the messages part:
    <MESSAGES>
    {conversation_text}
    </MESSAGES>
    """

    try:
        OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
        if not OPENROUTER_API_KEY:
            raise ValueError("OPENROUTER_API_KEY environment variable is not set")

        sum_client = OpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=OPENROUTER_API_KEY,
        )
        model = MAIN_MODEL
        response = sum_client.chat.completions.create(
            model=model, messages=[{"role": "user", "content": summary_prompt}]
        )
        logger.debug(f"Reorganize context API response: {response}")
        if not response or not response.choices:
            raise ValueError("No response received from OpenRouter API")

        summary = response.choices[0].message.content
        logger.debug(f"Reorganized context summary: {summary[:500]}...") # Log snippet
        if not summary:
            raise ValueError("Empty response content from OpenRouter API")

        start_tag = "<COMPLETED>"
        end_tag = "</COMPLETED>"
        if start_tag in summary and end_tag in summary:
            completed_items = summary[
                summary.find(start_tag) + len(start_tag) : summary.find(end_tag)
            ]
        else:
            completed_items = "No completed items found."

        start_tag = "<NEXT_STEPS>"
        end_tag = "</NEXT_STEPS>"
        if start_tag in summary and end_tag in summary:
            steps = summary[
                summary.find(start_tag) + len(start_tag) : summary.find(end_tag)
            ]
        else:
            steps = "No steps found."

        return completed_items, steps

    except Exception as e:
        logger.error(f"Error in reorganize_context: {str(e)}", exc_info=True)
        # Return default values in case of error
        return (
            "Error processing context. Please try again.",
            "Error processing steps. Please try again.",
        )

@retry(
    stop=stop_after_attempt(max_attempt_number=5),
    wait=wait_random_exponential(multiplier=2, min=4, max=10),
)
async def refresh_context_async(
    task: str, messages: List[Dict], display: Union[WebUI, AgentDisplayConsole], client
) -> str:
    """
    Create a combined context string by filtering and (if needed) summarizing messages
    and appending current file contents.
    """
    filtered = filter_messages(messages)
    summary = get_all_summaries() # This is a local function in context_helpers
    completed, next_steps = await reorganize_context(filtered, summary)

    file_contents = aggregate_file_states()
    if len(file_contents) > 200000:
        file_contents = (
            file_contents[:70000] + " ... [TRUNCATED] ... " + file_contents[-70000:]
        )

    # Get code skeletons
    from utils.file_logger import get_all_current_skeleton
    from utils.file_logger import get_all_current_code
    code_skeletons = get_all_current_skeleton()
    current_code = get_all_current_code()
    # The logic is if there is code, then supply that, if not then supply the skeletons, if there is no code or skeletons, then say there are no code skeletons

    if current_code:
        code_skeletons = current_code
    elif not code_skeletons or code_skeletons == "No Python files have been tracked yet.":
        code_skeletons = "No code skeletons available."

    # Extract information about images generated
    images_info = ""
    if "## Generated Images:" in file_contents:
        images_section = file_contents.split("## Generated Images:")[1]
        if "##" in images_section:
            images_section = images_section.split("##")[0]
        images_info = "## Generated Images:\n" + images_section.strip()

    # call the LLM and pass it all current messages then the task and ask it to give an updated version of the task
    prompt = f""" Your job is to update the task based on the current state of the project.
    The task is: {task}
    The current state of the project is:
    {file_contents}
    {code_skeletons}
    {completed}
    {next_steps}
    {images_info}

    Once again, here is the task that I need you to give an updated version of.  
    Make sure that you give any tips, lessons learned,  what has been done, and what needs to be done.
    Make sure you give clear guidance on how to import various files and in general how they should work together.
    """

    messages_for_llm = [{"role": "user", "content": prompt}]
    response = client.chat.completions.create(
        model=MAIN_MODEL,
        messages=messages_for_llm, # Corrected variable name
        max_tokens=get_constant("MAX_SUMMARY_TOKENS", 20000) # Use get_constant
    )
    new_task = response.choices[0].message.content

    combined_content = f"""Original request: 
    {task}
    
    IMPORTANT: This is a CONTINUING PROJECT. All files listed below ALREADY EXIST and are FULLY FUNCTIONAL.
    DO NOT recreate any existing files or redo completed steps. Continue the work from where it left off.

    Current Project Files and Assets:
    {file_contents}

    Code Skeletons (Structure of Python files):
    {code_skeletons}

    COMPLETED STEPS (These have ALL been successfully completed - DO NOT redo these):
    {completed}

    NEXT STEPS (Continue the project by completing these):
    {next_steps}


    Updated Request:
    {new_task}
    NOTES: 
    - All files mentioned in completed steps ALREADY EXIST in the locations specified.
    - All completed steps have ALREADY BEEN DONE successfully.
    - Continue the project by implementing the next steps, building on the existing work.
    """
    logger.info(f"Refreshed context combined_content (first 500 chars): {combined_content[:500]}...")
    return combined_content
</file>

<file path="file_logger.py">
import json
import datetime
import shutil
from pathlib import Path
from config import get_constant, LOGS_DIR

import ast
from typing import Union
import os
import mimetypes
import base64
import logging

logger = logging.getLogger(__name__)

try:
    from config import get_constant

    # Import the function but don't redefine it
    try:
        from config import convert_to_docker_path
    except ImportError:
        # Define our own if not available in config
        def convert_to_docker_path(path: Union[str, Path]) -> str:
            """
            Convert a local Windows path to a Docker container path.
            No longer converts to Docker path, returns original path.
            Args:
                path: The local path to convert

            Returns:
                The original path as a string
            """
            if isinstance(path, Path):
                return str(path)
            return path if path is not None else ""
except ImportError:
    # Fallback if config module is not available
    def get_constant(name):
        # Default values for essential constants
        defaults = {
            "LOG_FILE": os.path.join(
                os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
                "logs",
                "file_log.json",
            ),
        }
        return defaults.get(name)

    def convert_to_docker_path(path: Union[str, Path]) -> str:
        """
        Convert a local Windows path to a Docker container path.
        No longer converts to Docker path, returns original path.
        Args:
            path: The local path to convert

        Returns:
            The original path as a string
        """
        if isinstance(path, Path):
            return str(path)
        return path if path is not None else ""


# File for logging operations
try:
    LOG_FILE = get_constant("LOG_FILE")
except:
    LOG_FILE = os.path.join(
        os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
        "logs",
        "file_log.json",
    )

# In-memory tracking of file operations # FILE_OPERATIONS removed
# FILE_OPERATIONS = {} # Removed

# Ensure log directory exists
os.makedirs(os.path.dirname(LOG_FILE), exist_ok=True)

# If log file doesn't exist, create an empty one
if not os.path.exists(LOG_FILE):
    with open(LOG_FILE, "w") as f:
        json.dump({"files": {}}, f)

# Track file operations # Removed unused global variables
# file_operations = [] # Removed
# tracked_files = set() # Removed
# file_contents = {} # Removed


def log_file_operation(
    file_path: Path, operation: str, content: str = None, metadata: dict = None
):
    """
    Log a file operation (create, update, delete) with enhanced metadata handling.

    Args:
        file_path: Path to the file
        operation: Type of operation ('create', 'update', 'delete')
        content: Optional content for the file
        metadata: Optional dictionary containing additional metadata (e.g., image generation prompt)
    """
    # Defensively initialize metadata to prevent NoneType errors
    if metadata is None:
        metadata = {}

    # Ensure file_path is a Path object
    if not isinstance(file_path, Path):
        file_path = Path(file_path)

    # Create a string representation of the file path for consistent logging
    file_path_str = str(file_path)

    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    extension = file_path.suffix.lower() if file_path.suffix else ""

    # Determine if the file is an image
    is_image = extension in [".png", ".jpg", ".jpeg", ".gif", ".webp", ".svg", ".bmp"]
    mime_type = mimetypes.guess_type(file_path_str)[0]
    if mime_type and mime_type.startswith("image/"):
        is_image = True

    # Track file operations in memory # Removed FILE_OPERATIONS update logic
    # if file_path_str not in FILE_OPERATIONS:
    #     FILE_OPERATIONS[file_path_str] = {
    #         "operations": [],
    #         "last_updated": timestamp,
    #         "extension": extension,
    #         "is_image": is_image,
    #         "mime_type": mime_type,
    #     }
    #
    # # Update the in-memory tracking
    # FILE_OPERATIONS[file_path_str]["operations"].append(
    #     {"timestamp": timestamp, "operation": operation}
    # )
    # FILE_OPERATIONS[file_path_str]["last_updated"] = timestamp

    # Load existing log data or create a new one
    log_data = {"files": {}}

    if os.path.exists(LOG_FILE):
        try:
            with open(LOG_FILE, "r") as f:
                log_data = json.load(f)
        except json.JSONDecodeError:
            # If the log file is corrupted, start fresh
            log_data = {"files": {}}

    # Create or update the file entry in the log
    if file_path_str not in log_data["files"]:
        log_data["files"][file_path_str] = {
            "operations": [],
            "metadata": {},
            "content": None,
            "extension": extension,
            "is_image": is_image,
            "mime_type": mime_type,
            "last_updated": timestamp,
        }

    # Add the operation to the log
    log_data["files"][file_path_str]["operations"].append(
        {"timestamp": timestamp, "operation": operation}
    )

    # Update the metadata if provided
    if metadata:
        # Ensure we have a metadata dictionary
        if "metadata" not in log_data["files"][file_path_str]:
            log_data["files"][file_path_str]["metadata"] = {}

        # Update with new metadata
        log_data["files"][file_path_str]["metadata"].update(metadata)

    # Store the content if provided, otherwise try to read it from the file
    file_content = content

    try:
        # Only try to read the file if it exists and content wasn't provided
        if file_content is None and file_path.exists() and file_path.is_file():
            try:
                # Handle different file types appropriately
                if is_image:
                    # For images, store base64 encoded content
                    with open(file_path, "rb") as f:
                        img_content = f.read()
                        log_data["files"][file_path_str]["content"] = base64.b64encode(
                            img_content
                        ).decode("utf-8")
                        # Add file size to metadata
                        if "metadata" not in log_data["files"][file_path_str]:
                            log_data["files"][file_path_str]["metadata"] = {}
                        log_data["files"][file_path_str]["metadata"]["size"] = len(
                            img_content
                        )

                elif extension in [".py", ".js", ".html", ".css", ".json", ".md"]:
                    # For code and text files, store as text
                    with open(file_path, "r", encoding="utf-8") as f:
                        text_content = f.read()
                        log_data["files"][file_path_str]["content"] = text_content

                else:
                    # For other binary files, store base64 encoded
                    with open(file_path, "rb") as f:
                        bin_content = f.read()
                        log_data["files"][file_path_str]["content"] = base64.b64encode(
                            bin_content
                        ).decode("utf-8")
                        # Add file size to metadata
                        if "metadata" not in log_data["files"][file_path_str]:
                            log_data["files"][file_path_str]["metadata"] = {}
                        log_data["files"][file_path_str]["metadata"]["size"] = len(
                            bin_content
                        )

            except Exception as read_error:
                logger.error(f"Error reading file content for {file_path_str}: {read_error}", exc_info=True)
                # Don't fail the entire operation, just log the error
                if "metadata" not in log_data["files"][file_path_str]:
                    log_data["files"][file_path_str]["metadata"] = {}
                log_data["files"][file_path_str]["metadata"]["read_error"] = str(
                    read_error
                )

        elif file_content is not None:
            # Use the provided content
            log_data["files"][file_path_str]["content"] = file_content

    except Exception as e:
        logger.error(f"Error processing file content for {file_path_str}: {e}", exc_info=True)
        # Don't fail the entire operation, just log the error
        if "metadata" not in log_data["files"][file_path_str]:
            log_data["files"][file_path_str]["metadata"] = {}
        log_data["files"][file_path_str]["metadata"]["processing_error"] = str(e)

    # Update last_updated timestamp
    log_data["files"][file_path_str]["last_updated"] = timestamp

    # Write the updated log data back to the log file
    try:
        with open(LOG_FILE, "w") as f:
            json.dump(log_data, f, indent=2)
    except Exception as write_error:
        logger.error(f"Error writing to log file {LOG_FILE}: {write_error}", exc_info=True)


def aggregate_file_states() -> str:
    """
    Collect information about all tracked files and their current state.

    Returns:
        A formatted string with information about all files.
    """
    LOG_FILE = Path(get_constant("LOG_FILE"))
    if not LOG_FILE.exists():
        return "No files have been tracked yet."

    try:
        with open(LOG_FILE, "r", encoding="utf-8") as f:
            log_data = json.loads(f.read())
    except (json.JSONDecodeError, FileNotFoundError):
        return "Error reading log file."

    if not log_data:
        return "No files have been tracked yet."

    # Group files by type
    image_files = []
    code_files = []
    text_files = []
    other_files = []

    for file_path, file_info in log_data.items():
        file_type = file_info.get("file_type", "other")

        # Get the Docker path for display
        docker_path = file_info.get("docker_path", convert_to_docker_path(file_path))

        # Sort operations by timestamp to get the latest state
        operations = sorted(
            file_info.get("operations", []),
            key=lambda x: x.get("timestamp", ""),
            reverse=True,
        )

        latest_operation = operations[0] if operations else {"operation": "unknown"}

        if file_type == "image":
            image_metadata = file_info.get("image_metadata", {})
            image_files.append(
                {
                    "path": docker_path,
                    "operation": latest_operation.get("operation"),
                    "prompt": image_metadata.get("prompt", "No prompt available"),
                    "dimensions": image_metadata.get("dimensions", "Unknown"),
                    "created_at": image_metadata.get(
                        "created_at", file_info.get("created_at", "Unknown")
                    ),
                }
            )
        elif file_type == "code":
            code_files.append(
                {
                    "path": docker_path,
                    "operation": latest_operation.get("operation"),
                    "content": file_info.get("content", ""),
                    "skeleton": file_info.get("skeleton", "No skeleton available"),
                }
            )
        elif file_type == "text":
            text_files.append(
                {
                    "path": docker_path,
                    "operation": latest_operation.get("operation"),
                    "content": file_info.get("content", ""),
                }
            )
        else:
            basic_info = file_info.get("basic_info", {})
            other_files.append(
                {
                    "path": docker_path,
                    "operation": latest_operation.get("operation"),
                    "mime_type": basic_info.get("mime_type", "Unknown"),
                    "size": basic_info.get("size", 0),
                }
            )

    # Format the output
    output = []

    if image_files:
        output.append("## Image Files")
        for img in image_files:
            output.append(f"### {img['path']}")
            output.append(f"- **Operation**: {img['operation']}")
            output.append(f"- **Created**: {img['created_at']}")
            output.append(f"- **Prompt**: {img['prompt']}")
            output.append(f"- **Dimensions**: {img['dimensions']}")
            output.append("")

    if code_files:
        output.append("## Code Files")
        for code in code_files:
            output.append(f"### {code['path']}")
            output.append(f"- **Operation**: {code['operation']}")

            # Add syntax highlighting based on file extension
            extension = Path(code["path"]).suffix.lower()
            lang = get_language_from_extension(extension)

            output.append("- **Structure**:")
            output.append(f"```{lang}")
            output.append(code["skeleton"])
            output.append("```")

            output.append("- **Content**:")
            output.append(f"```{lang}")
            output.append(code["content"])
            output.append("```")
            output.append("")

    if text_files:
        output.append("## Text Files")
        for text in text_files:
            output.append(f"### {text['path']}")
            output.append(f"- **Operation**: {text['operation']}")

            # Add syntax highlighting based on file extension
            extension = Path(text["path"]).suffix.lower()
            lang = get_language_from_extension(extension)

            output.append("- **Content**:")
            output.append(f"```{lang}")
            output.append(text["content"])
            output.append("```")
            output.append("")

    if other_files:
        output.append("## Other Files")
        for other in other_files:
            output.append(f"### {other['path']}")
            output.append(f"- **Operation**: {other['operation']}")
            output.append(f"- **MIME Type**: {other['mime_type']}")
            output.append(f"- **Size**: {other['size']} bytes")
            output.append("")

    return "\n".join(output)


def extract_code_skeleton(source_code: Union[str, Path]) -> str:
    """
    Extract a code skeleton from existing Python code.

    This function takes Python code and returns just the structure: imports,
    class definitions, method/function signatures, and docstrings, with
    implementations replaced by 'pass' statements.

    Args:
        source_code: Either a path to a Python file or a string containing Python code

    Returns:
        str: The extracted code skeleton
    """
    # Load the source code
    if isinstance(source_code, (str, Path)) and Path(source_code).exists():
        with open(source_code, "r", encoding="utf-8") as file:
            code_str = file.read()
    else:
        code_str = str(source_code)

    # Parse the code into an AST
    try:
        tree = ast.parse(code_str)
    except SyntaxError as e:
        return f"# Error parsing code: {e}\n{code_str}"

    # Extract imports
    imports = []
    for node in ast.walk(tree):
        if isinstance(node, ast.Import):
            for name in node.names:
                imports.append(
                    f"import {name.name}"
                    + (f" as {name.asname}" if name.asname else "")
                )
        elif isinstance(node, ast.ImportFrom):
            module = node.module or ""
            names = ", ".join(
                name.name + (f" as {name.asname}" if name.asname else "")
                for name in node.names
            )
            imports.append(f"from {module} import {names}")

    # Helper function to handle complex attributes
    def format_attribute(node):
        """Helper function to recursively format attribute expressions"""
        if isinstance(node, ast.Name):
            return node.id
        elif isinstance(node, ast.Attribute):
            return f"{format_attribute(node.value)}.{node.attr}"
        # Add support for ast.Subscript nodes (like List[int])
        elif isinstance(node, ast.Subscript):
            # Use ast.unparse for Python 3.9+ or manual handling for earlier versions
            if hasattr(ast, "unparse"):
                return ast.unparse(node)
            else:
                # Simplified handling for common cases
                if isinstance(node.value, ast.Name):
                    base = node.value.id
                else:
                    base = format_attribute(node.value)
                # Simple handling for slice
                if isinstance(node.slice, ast.Index) and hasattr(node.slice, "value"):
                    if isinstance(node.slice.value, ast.Name):
                        return f"{base}[{node.slice.value.id}]"
                    else:
                        return f"{base}[...]"  # Fallback for complex slices
                return f"{base}[...]"  # Fallback for complex cases
        else:
            # Fallback for other node types - use ast.unparse if available
            if hasattr(ast, "unparse"):
                return ast.unparse(node)
            return str(node)

    # Get docstrings and function/class signatures
    class CodeSkeletonVisitor(ast.NodeVisitor):
        def __init__(self):
            self.skeleton = []
            self.indent_level = 0
            self.imports = []

        def visit_Import(self, node):
            # Already handled above
            pass

        def visit_ImportFrom(self, node):
            # Already handled above
            pass

        def visit_ClassDef(self, node):
            # Extract class definition with inheritance
            bases = []
            for base in node.bases:
                if isinstance(base, ast.Name):
                    bases.append(base.id)
                elif isinstance(base, ast.Attribute):
                    # Use the helper function to handle nested attributes
                    bases.append(format_attribute(base))
                else:
                    # Fallback for other complex cases
                    if hasattr(ast, "unparse"):
                        bases.append(ast.unparse(base))
                    else:
                        bases.append("...")

            class_def = f"class {node.name}"
            if bases:
                class_def += f"({', '.join(bases)})"
            class_def += ":"

            # Add class definition
            self.skeleton.append("\n" + "    " * self.indent_level + class_def)

            # Add docstring if it exists
            docstring = ast.get_docstring(node)
            if docstring:
                doc_lines = docstring.split("\n")
                if len(doc_lines) == 1:
                    self.skeleton.append(
                        "    " * (self.indent_level + 1) + f'"""{docstring}"""'
                    )
                else:
                    self.skeleton.append("    " * (self.indent_level + 1) + '"""')
                    for line in doc_lines:
                        self.skeleton.append("    " * (self.indent_level + 1) + line)
                    self.skeleton.append("    " * (self.indent_level + 1) + '"""')

            # Increment indent for class members
            self.indent_level += 1

            # Visit all class members
            for item in node.body:
                if not isinstance(item, ast.Expr) or not isinstance(
                    item.value, ast.Str
                ):
                    self.visit(item)

            # If no members were added, add a pass statement
            if len(self.skeleton) > 0 and not self.skeleton[-1].strip().startswith(
                "def "
            ):
                if "pass" not in self.skeleton[-1]:
                    self.skeleton.append("    " * self.indent_level + "pass")

            # Restore indent
            self.indent_level -= 1

        def visit_FunctionDef(self, node):
            # Extract function signature
            args = []
            defaults = [None] * (
                len(node.args.args) - len(node.args.defaults)
            ) + node.args.defaults

            # Process regular arguments
            for i, arg in enumerate(node.args.args):
                arg_str = arg.arg
                # Add type annotation if available
                if arg.annotation:
                    # Use the helper function to handle complex types
                    if hasattr(ast, "unparse"):
                        arg_str += f": {ast.unparse(arg.annotation)}"
                    else:
                        if isinstance(arg.annotation, ast.Name):
                            arg_str += f": {arg.annotation.id}"
                        elif isinstance(arg.annotation, ast.Attribute):
                            arg_str += f": {format_attribute(arg.annotation)}"
                        elif isinstance(arg.annotation, ast.Subscript):
                            arg_str += f": {format_attribute(arg.annotation)}"
                        else:
                            arg_str += ": ..."  # Fallback for complex annotations

                # Add default value if available
                if defaults[i] is not None:
                    if hasattr(ast, "unparse"):
                        arg_str += f" = {ast.unparse(defaults[i])}"
                    else:
                        # Simplified handling for common default values
                        if isinstance(
                            defaults[i], (ast.Str, ast.Num, ast.NameConstant)
                        ):
                            arg_str += f" = {ast.literal_eval(defaults[i])}"
                        elif isinstance(defaults[i], ast.Name):
                            arg_str += f" = {defaults[i].id}"
                        elif isinstance(defaults[i], ast.Attribute):
                            arg_str += f" = {format_attribute(defaults[i])}"
                        else:
                            arg_str += " = ..."  # Fallback for complex defaults

                args.append(arg_str)

            # Handle *args
            if node.args.vararg:
                args.append(f"*{node.args.vararg.arg}")

            # Handle keyword-only args
            if node.args.kwonlyargs:
                if not node.args.vararg:
                    args.append("*")
                for i, kwarg in enumerate(node.args.kwonlyargs):
                    kw_str = kwarg.arg
                    if kwarg.annotation:
                        if hasattr(ast, "unparse"):
                            kw_str += f": {ast.unparse(kwarg.annotation)}"
                        else:
                            kw_str += f": {format_attribute(kwarg.annotation)}"
                    if (
                        i < len(node.args.kw_defaults)
                        and node.args.kw_defaults[i] is not None
                    ):
                        if hasattr(ast, "unparse"):
                            kw_str += f" = {ast.unparse(node.args.kw_defaults[i])}"
                        else:
                            kw_str += " = ..."  # Fallback for complex defaults
                    args.append(kw_str)

            # Handle **kwargs
            if node.args.kwarg:
                args.append(f"**{node.args.kwarg.arg}")

            # Build function signature
            func_def = f"def {node.name}({', '.join(args)})"

            # Add return type if specified
            if node.returns:
                if hasattr(ast, "unparse"):
                    func_def += f" -> {ast.unparse(node.returns)}"
                else:
                    func_def += f" -> {format_attribute(node.returns)}"

            func_def += ":"

            # Add function definition
            self.skeleton.append("\n" + "    " * self.indent_level + func_def)

            # Add docstring if it exists
            docstring = ast.get_docstring(node)
            if docstring:
                doc_lines = docstring.split("\n")
                if len(doc_lines) == 1:
                    self.skeleton.append(
                        "    " * (self.indent_level + 1) + f'"""{docstring}"""'
                    )
                else:
                    self.skeleton.append("    " * (self.indent_level + 1) + '"""')
                    for line in doc_lines:
                        self.skeleton.append("    " * (self.indent_level + 1) + line)
                    self.skeleton.append("    " * (self.indent_level + 1) + '"""')

            # Add pass statement in place of the function body
            self.skeleton.append("    " * (self.indent_level + 1) + "pass")

    # Run the visitor on the AST
    visitor = CodeSkeletonVisitor()
    visitor.visit(tree)

    # Combine imports and code skeleton
    result = []

    # Add all imports first
    if imports:
        result.extend(imports)
        result.append("")  # Add a blank line after imports

    # Add the rest of the code skeleton
    result.extend(visitor.skeleton)

    return "\n".join(result)


def get_all_current_code() -> str:
    """
    Returns all the current code in the project as a string.
    This function is used to provide context about the existing code to the LLM.

    Returns:
        A string with all the current code.
    """
    try:
        # Ensure log file exists
        if not os.path.exists(LOG_FILE):
            logger.warning(f"Log file not found: {LOG_FILE}")
            # Initialize a new log file so future operations work
            with open(LOG_FILE, "w") as f:
                json.dump({"files": {}}, f)
            return "No code has been written yet."

        # Load log data with robust error handling
        try:
            with open(LOG_FILE, "r", encoding="utf-8") as f:
                log_data = json.load(f)
        except json.JSONDecodeError:
            logger.error(f"Log file contains invalid JSON: {LOG_FILE}")
            # Reset the log file with valid JSON
            with open(LOG_FILE, "w") as f:
                json.dump({"files": {}}, f)
            return "Error reading log file. Log file has been reset."
        except Exception as e:
            logger.error(f"Unexpected error reading log file: {e}", exc_info=True)
            return f"Error reading log file: {str(e)}"

        # Validate log structure
        if not isinstance(log_data, dict) or "files" not in log_data:
            logger.error("Log file has invalid format (missing 'files' key)")
            # Fix the format
            log_data = {"files": {}}
            with open(LOG_FILE, "w") as f:
                json.dump(log_data, f)
            return "Error reading log file. Log file has been reset with correct structure."

        output = []
        code_files = []

        # Process each file in the log
        for file_path, file_data in log_data.get("files", {}).items():
            try:
                # Skip files that have been deleted (last operation is 'delete')
                operations = file_data.get("operations", [])
                if operations and operations[-1].get("operation") == "delete":
                    continue

                # Get content and metadata
                content = file_data.get("content")
                if content is None:
                    continue

                # Skip images and binary files
                is_image = file_data.get("is_image", False)
                mime_type = file_data.get("mime_type", "")
                extension = file_data.get("extension", "").lower()

                if is_image or (mime_type and mime_type.startswith("image/")):
                    continue

                # Only include code files
                if extension in [
                    ".py",
                    ".js",
                    ".html",
                    ".css",
                    ".ts",
                    ".jsx",
                    ".tsx",
                    ".java",
                    ".cpp",
                    ".c",
                    ".h",
                    ".cs",
                ]:
                    code_files.append(
                        {"path": file_path, "content": content, "extension": extension}
                    )
            except Exception as file_error:
                logger.error(f"Error processing file {file_path}: {file_error}", exc_info=True)
                # Continue processing other files

        # Sort files by path for consistent output
        code_files.sort(key=lambda x: x["path"])

        # Format the output
        output.append("# Code\n")

        if code_files:
            for code in code_files:
                try:
                    output.append(f"## {code['path']}")
                    lang = get_language_from_extension(code["extension"])
                    output.append(f"```{lang}")
                    output.append(code["content"])
                    output.append("```\n")
                except Exception as format_error:
                    logger.error( # Replaced print with logger.error
                        f"Error formatting code file {code.get('path')}: {format_error}", exc_info=True
                    )
                    # Add a simpler version without failing
                    output.append(f"## {code.get('path', 'Unknown file')}")
                    output.append("```")
                    output.append("Error displaying file content")
                    output.append("```\n")
        else:
            output.append("No code files have been created yet.\n")

        # Return the formatted output (This was missing)
        return "\n".join(output)

    except Exception as e:
        logger.critical(f"Critical error in get_all_current_code: {e}", exc_info=True)
        return "Error reading code files. Please check application logs for details."


def get_all_current_skeleton() -> str:
    """
    Get the skeleton of all Python code files.

    Returns:
        A formatted string with the skeleton of all Python code files.
    """
    LOG_FILE = Path(get_constant("LOG_FILE"))
    if not LOG_FILE.exists():
        return "No Python files have been tracked yet."

    try:
        with open(LOG_FILE, "r", encoding="utf-8") as f:
            log_data = json.load(f)
    except (json.JSONDecodeError, FileNotFoundError):
        return "Error reading log file."

    if not log_data or not log_data.get("files"):
        return "No Python files have been tracked yet."

    output = ["# All Python File Skeletons"]

    for file_path, file_info in log_data.get("files", {}).items():
        # Skip files that have been deleted (last operation is 'delete')
        operations = file_info.get("operations", [])
        if operations and operations[-1].get("operation") == "delete":
            continue

        # Only process Python files
        extension = file_info.get("extension", "").lower()
        if extension != ".py":
            continue

        # Get Docker path for display
        docker_path = convert_to_docker_path(file_path)

        # Look for skeleton in metadata
        metadata = file_info.get("metadata", {})
        skeleton = metadata.get("skeleton", "")

        # If no skeleton in metadata, try to extract it from the content
        if not skeleton and file_info.get("content"):
            try:
                skeleton = extract_code_skeleton(file_info.get("content", ""))
            except Exception as e:
                logger.error(f"Error extracting skeleton from {file_path}: {e}", exc_info=True)
                skeleton = "# Failed to extract skeleton"

        if skeleton:
            # Add file header
            output.append(f"## {docker_path}")

            # Add skeleton with syntax highlighting
            output.append("```python")
            output.append(skeleton)
            output.append("```")
            output.append("")

    return "\n".join(output)


def get_language_from_extension(extension: str) -> str:
    """
    Map file extensions to programming languages for syntax highlighting.

    Args:
        extension: The file extension (e.g., '.py', '.js')

    Returns:
        The corresponding language name for syntax highlighting.
    """
    extension = extension.lower()
    mapping = {
        ".py": "python",
        ".js": "javascript",
        ".jsx": "javascript",
        ".ts": "typescript",
        ".tsx": "typescript",
        ".html": "html",
        ".css": "css",
        ".json": "json",
        ".md": "markdown",
        ".yaml": "yaml",
        ".yml": "yaml",
        ".toml": "toml",
        ".java": "java",
        ".cpp": "cpp",
        ".c": "c",
        ".cs": "csharp",
        ".sh": "bash",
        ".rb": "ruby",
        ".go": "go",
        ".php": "php",
        ".rs": "rust",
        ".swift": "swift",
        ".kt": "kotlin",
        ".sql": "sql",
    }
    return mapping.get(extension, "")


def should_skip_for_zip(path):
    """
    Determine if a file or directory should be skipped when creating a ZIP file.

    Args:
        path: Path to check

    Returns:
        bool: True if the path should be skipped, False otherwise
    """
    path_str = str(path).lower()

    # Skip virtual environment files and directories
    if ".venv" in path_str:
        # On Windows, particularly skip Linux-style virtual env paths
        if os.name == "nt" and ("bin/" in path_str or "lib/" in path_str):
            return True

    # Skip common directories not needed in the ZIP
    dirs_to_skip = [
        "__pycache__",
        ".git",
        ".idea",
        ".vscode",
        "node_modules",
        ".pytest_cache",
    ]

    return any(skip_dir in path_str for skip_dir in dirs_to_skip)


def archive_logs():
    """Archive all log files in LOGS_DIR by moving them to an archive folder with a timestamp."""
    try:
        # Create timestamp for the archive folder
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        archive_dir = Path(LOGS_DIR, "archive", timestamp)
        archive_dir.mkdir(parents=True, exist_ok=True)

        # Get all files in LOGS_DIR
        log_path = Path(LOGS_DIR)
        log_files = [f for f in log_path.iterdir() if f.is_file()]

        # Skip archiving if there are no files
        if not log_files:
            return "No log files to archive"

        # Move each file to the archive directory
        for file_path in log_files:
            # Skip archive directory itself
            if "archive" in str(file_path):
                continue

            # Create destination path
            dest_path = Path(archive_dir, file_path.name)

            # Copy the file if it exists (some might be created later)
            if file_path.exists():
                shutil.copy2(file_path, dest_path)

                # Clear the original file but keep it
                with open(file_path, "w") as f:
                    f.write("")

        return f"Archived {len(log_files)} log files to {archive_dir}"
    except Exception as e:
        return f"Error archiving files: {str(e)}"
</file>

<file path="llm_client.py">
import logging
import os
import aiohttp
from typing import Dict, List
from abc import ABC, abstractmethod

logger = logging.getLogger(__name__)

class LLMClient(ABC):
    """Abstract base class for LLM clients."""
    
    @abstractmethod
    async def call(self, messages: List[Dict[str, str]], max_tokens: int = 200, temperature: float = 0.1) -> str:
        """Call the LLM with messages and return response."""
        pass

class OpenRouterClient(LLMClient):
    """OpenRouter API client."""
    
    def __init__(self, model: str):
        self.model = model
        self.api_key = os.environ.get("OPENROUTER_API_KEY")
        if not self.api_key:
            raise ValueError("OPENROUTER_API_KEY environment variable not set")
    
    async def call(self, messages: List[Dict[str, str]], max_tokens: int = 200, temperature: float = 0.1) -> str:
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            "HTTP-Referer": "https://github.com/command-converter",
            "X-Title": "Command Converter"
        }
        
        payload = {
            "model": self.model,
            "messages": messages,
            "max_tokens": max_tokens,
            "temperature": temperature,
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers=headers,
                json=payload,
                timeout=aiohttp.ClientTimeout(total=30)
            ) as response:
                if response.status != 200:
                    error_text = await response.text()
                    raise RuntimeError(f"OpenRouter API error: {response.status} - {error_text}")
                
                result = await response.json()
                
                if "choices" not in result or not result["choices"]:
                    raise RuntimeError("Invalid OpenRouter response format")
                
                return result["choices"][0]["message"]["content"]

class OpenAIClient(LLMClient):
    """OpenAI API client."""
    
    def __init__(self, model: str):
        self.model = model
        self.api_key = os.environ.get("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError("OPENAI_API_KEY environment variable not set")
    
    async def call(self, messages: List[Dict[str, str]], max_tokens: int = 200, temperature: float = 0.1) -> str:
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
        }
        
        payload = {
            "model": self.model,
            "messages": messages,
            "max_tokens": max_tokens,
            "temperature": temperature,
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "https://api.openai.com/v1/chat/completions",
                headers=headers,
                json=payload,
                timeout=aiohttp.ClientTimeout(total=30)
            ) as response:
                if response.status != 200:
                    error_text = await response.text()
                    raise RuntimeError(f"OpenAI API error: {response.status} - {error_text}")
                
                result = await response.json()
                
                if "choices" not in result or not result["choices"]:
                    raise RuntimeError("Invalid OpenAI response format")
                
                return result["choices"][0]["message"]["content"]

class AnthropicClient(LLMClient):
    """Anthropic API client."""
    
    def __init__(self, model: str):
        self.model = model
        self.api_key = os.environ.get("ANTHROPIC_API_KEY")
        if not self.api_key:
            raise ValueError("ANTHROPIC_API_KEY environment variable not set")
    
    async def call(self, messages: List[Dict[str, str]], max_tokens: int = 200, temperature: float = 0.1) -> str:
        headers = {
            "x-api-key": self.api_key,
            "Content-Type": "application/json",
            "anthropic-version": "2023-06-01"
        }
        
        # Convert messages format for Anthropic
        system_content = ""
        user_messages = []
        
        for msg in messages:
            if msg["role"] == "system":
                system_content = msg["content"]
            else:
                user_messages.append(msg)
        
        payload = {
            "model": self.model,
            "max_tokens": max_tokens,
            "temperature": temperature,
            "messages": user_messages,
        }
        
        if system_content:
            payload["system"] = system_content
        
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "https://api.anthropic.com/v1/messages",
                headers=headers,
                json=payload,
                timeout=aiohttp.ClientTimeout(total=30)
            ) as response:
                if response.status != 200:
                    error_text = await response.text()
                    raise RuntimeError(f"Anthropic API error: {response.status} - {error_text}")
                
                result = await response.json()
                
                if "content" not in result or not result["content"]:
                    raise RuntimeError("Invalid Anthropic response format")
                
                return result["content"][0]["text"]

def create_llm_client(model: str) -> LLMClient:
    """Factory function to create appropriate LLM client based on model name."""
    if model.startswith("anthropic/"):
        return OpenRouterClient(model)
    elif model.startswith("openai/"):
        return OpenRouterClient(model)
    elif model.startswith("google/"):
        return OpenRouterClient(model)
    elif model.startswith("gpt-"):
        return OpenAIClient(model)
    elif model.startswith("claude-"):
        return AnthropicClient(model)
    else:
        # Default to OpenRouter for unknown models
        logger.warning(f"Unknown model format: {model}, defaulting to OpenRouter")
        return OpenRouterClient(model)
</file>

<file path="miniOR.py">
import os

from dotenv import load_dotenv
from openai import AsyncOpenAI, OpenAI

load_dotenv()

openai41mini : str = "openai/gpt-4.1-mini"
gemma3n4b : str = "google/gemma-3n-e4b-it"
sonnet4 : str = "anthropic/claude-sonnet-4"
openai41 : str = "openai/gpt-4.1"
openaio3 : str = "openai/o3"
openaio3pro : str = "openai/o3-pro"
googlepro : str = "google/gemini-2.5-pro-preview"
googleflash : str = "google/gemini-2.5-flash-preview"
googleflashlite : str = "google/gemini-2.5-flash-lite-preview-06-17"
grok4 : str = "x-ai/grok-4"
SUMMARY_MODEL : str = googleflashlite  # Model for summaries
MAIN_MODEL : str = f"{googleflashlite}"  # Primary model for main agent operations
CODE_MODEL : str = f"{googleflashlite}:web"  # Model for code generation tasks
BASE_URL : str = "https://openrouter.ai/api/v1"
DEFAULT_MODEL : str = MAIN_MODEL

BASE_SYSTEM_PROMPT : str = "You are a helpful AI assistant. "


def get_llm(
    base_url : str = BASE_URL,
    api_key : str = str(os.getenv("OPENROUTER_API_KEY")),
    is_async : bool = False,
) -> OpenAI | AsyncOpenAI:
    """
    Get the appropriate LLM instance based on the async flag.
    """
    if is_async:
        return AsyncOpenAI(
            base_url=base_url,
            api_key=api_key or os.getenv("OPENROUTER_API_KEY"),
        )
    else:
        return OpenAI(
            base_url=base_url,
            api_key=api_key or os.getenv("OPENROUTER_API_KEY"),
        )


def chat(prompt_str, model=os.getenv("OPENROUTER_MODEL", DEFAULT_MODEL)):
    """
    Send a chat message to the LLM.
    
    """
    llm = get_llm()
    messages = [{"role": "user", "content": prompt_str}]
    if isinstance(llm, AsyncOpenAI):

        return llm.chat.completions.create(messages=messages, model=model).choices[0].message.content
    else:
        return llm.chat.completions.create(messages=messages, model=model).choices[0].message.content


if __name__ == "__main__":
    # Example usage
    response = chat(prompt_str="Hello, how can you assist me today?")
    print(response)
</file>

<file path="output_manager.py">
import base64
import hashlib
import json
from datetime import datetime
from pathlib import Path
from typing import Any, List, Optional, TYPE_CHECKING, Union

from typing import Dict
import logging

from .web_ui import WebUI
from .agent_display_console import AgentDisplayConsole
from config import get_constant  # Updated import

logger = logging.getLogger(__name__)

if TYPE_CHECKING:
    from tools.base import ToolResult


class OutputManager:

    def __init__(self,
                 display: Union[WebUI, AgentDisplayConsole],
                 image_dir: Optional[Path] = None):
        LOGS_DIR = Path(get_constant("LOGS_DIR"))
        self.image_dir = LOGS_DIR / "computer_tool_images"
        self.image_dir.mkdir(parents=True, exist_ok=True)
        self.image_counter = 0
        self.display = display

    def save_image(self, base64_data: str) -> Optional[Path]:
        """Save base64 image data to file and return path."""
        if not base64_data:
            logger.error("No base64 data provided to save_image")
            return None

        try:
            self.image_counter += 1
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            image_hash = hashlib.md5(base64_data.encode()).hexdigest()[:8]
            image_path = self.image_dir / f"image_{timestamp}_{image_hash}.png"

            image_data = base64.b64decode(base64_data)
            with open(image_path, "wb") as f:
                f.write(image_data)
            return image_path
        except Exception as e:
            logger.error(f"Error saving image: {e}", exc_info=True)
            return None

    def format_tool_output(self, result: "ToolResult", tool_name: str):
        """Format and display tool output."""
        if result is None:
            logger.error("None result provided to format_tool_output")
            return

        output_text = f"Used Tool: {tool_name}\n"

        if isinstance(result, str):
            output_text += f"{result}"
        else:
            text = self._truncate_string(
                str(result.output) if result.output is not None else "")
            output_text += f"Output: {text}\n"
            if result.base64_image:
                image_path = self.save_image(result.base64_image)
                if image_path:
                    output_text += (
                        f"[green]📸 Screenshot saved to {image_path}[/green]\n")
                else:
                    output_text += "[red]Failed to save screenshot[/red]\n"

        # self.display., output_text)

    def format_api_response(self, response: Dict[str, Any]):
        """Format and display API response."""
        if response is None or not hasattr(response,
                                           "content") or not response.content:
            logger.error("Invalid API response in format_api_response")
            return

        if response.content and hasattr(response.content[0], "text"):
            self._truncate_string(response.content[0].text)

    def format_content_block(self, block: Dict[str, Any]) -> None:
        """Format and display content block."""
        if block is None:
            logger.error("None block provided to format_content_block")
            return

        if getattr(block, "type", None) == "tool_use":
            safe_input = {
                k: v
                for k, v in block.input.items()
                if not isinstance(v, str) or len(v) < 1000
            }
            json.dumps(safe_input) if isinstance(safe_input,
                                                 dict) else str(safe_input)

    def format_recent_conversation(self,
                                   messages: List[Dict[str, Any]],
                                   num_recent: int = 10):
        """Format and display recent conversation."""
        if messages is None or not messages:
            logger.warning(
                "No messages provided to format_recent_conversation")
            return

        # recent_messages = messages[:num_recent] if len(messages) > num_recent else messages
        recent_messages = messages[-num_recent:]
        for msg in recent_messages:
            if msg["role"] == "user":
                self._format_user_content(msg["content"])
            elif msg["role"] == "assistant":
                self._format_assistant_content(msg["content"])

    def _format_user_content(self, content: Any):
        """Format and display user content."""
        if content is None:
            logger.error("None content provided to _format_user_content")
            return

        if isinstance(content, list):
            for content_block in content:
                if isinstance(content_block, dict):
                    if content_block.get("type") == "tool_result":
                        for item in content_block.get("content", []):
                            if item.get("type") == "text":
                                self._truncate_string(item.get("text", ""))
                            #     self.display., text)
                            # elif item.get("type") == "image":
                            #     self.display., "📸 Screenshot captured")
        elif isinstance(content, str):
            self._truncate_string(content)
            # self.display., text)

    def _format_assistant_content(self, content: Any):
        """Format and display assistant content."""
        if content is None:
            logger.error("None content provided to _format_assistant_content")
            return

        if isinstance(content, list):
            for content_block in content:
                if isinstance(content_block, dict):
                    if content_block.get("type") == "text":
                        self._truncate_string(content_block.get("text", ""))
                    elif content_block.get("type") == "tool_use":
                        content_block.get("name")
                        tool_input = content_block.get("input", "")
                        if isinstance(tool_input, dict):
                            "\n".join(f"{k}: {v}"
                                      for k, v in tool_input.items())
                        else:
                            try:
                                tool_input = json.loads(tool_input)
                                "\n".join(f"{k}: {v}"
                                          for k, v in tool_input.items())
                            except json.JSONDecodeError:
                                str(tool_input)
                        # self.display., (tool_name, f"Input: {input_text}"))
        elif isinstance(content, str):
            self._truncate_string(content)

    def _truncate_string(self, text: str, max_length: int = 500) -> str:
        """Truncate a string to a max length with ellipsis."""
        if text is None:
            return ""

        if len(text) > max_length:
            return text[:200] + "\n...\n" + text[-200:]
        return text
</file>

<file path="web_ui.py">
import asyncio
import os
import logging
import json
from queue import Queue
from flask import Flask, render_template, jsonify, request
from flask_socketio import SocketIO
from config import (
    LOGS_DIR,
    PROMPTS_DIR,
    get_constant,
    set_constant,
    set_prompt_name,
    write_constants_to_file,
)
from pathlib import Path


logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def log_message(msg_type, message):
    """Log a message to a file."""
    if msg_type == "user":
        emojitag = "🤡 "
    elif msg_type == "assistant":
        emojitag = "🧞‍♀️ "
    elif msg_type == "tool":
        emojitag = "📎 "
    else:
        emojitag = "❓ "
    log_file = os.path.join(LOGS_DIR, f"{msg_type}_messages.log")
    with open(log_file, "a", encoding="utf-8") as file:
        file.write(emojitag * 5)
        file.write(f"\n{message}\n\n")

class WebUI:
    def __init__(self, agent_runner):
        logging.info("Initializing WebUI")
        # More robust path for templates
        template_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'templates'))
        logging.info(f"Template directory set to: {template_dir}")
        self.app = Flask(__name__, template_folder=template_dir)
        self.app.config["SECRET_KEY"] = "secret!"
        self.socketio = SocketIO(self.app, async_mode="threading", cookie=None)
        self.user_messages = []
        self.assistant_messages = []
        self.tool_results = []
        # Using a standard Queue for cross-thread communication
        self.input_queue = Queue()
        self.tool_queue = Queue()
        self.agent_runner = agent_runner
        # Import tools lazily to avoid circular imports
        from tools import (
            # BashTool,
            # OpenInterpreterTool,
            ProjectSetupTool,
            WriteCodeTool,
            PictureGenerationTool,
            EditTool,
            ToolCollection,
            BashTool
        )

        self.tool_collection = ToolCollection(
            WriteCodeTool(display=self),
            ProjectSetupTool(display=self),
            BashTool(display=self),
            # OpenInterpreterTool(display=self),  # Uncommented and enabled for testing
            PictureGenerationTool(display=self),
            EditTool(display=self),
            display=self,
        )
        self.setup_routes()
        self.setup_socketio_events()
        logging.info("WebUI initialized")

    def setup_routes(self):
        logging.info("Setting up routes")

        @self.app.route("/")
        def select_prompt_route():
            logging.info("Serving modern prompt selection page (default)")
            prompt_files = list(PROMPTS_DIR.glob("*.md"))
            options = [file.name for file in prompt_files]
            return render_template("select_prompt_modern.html", options=options)

        @self.app.route("/classic")
        def select_prompt_classic_route():
            logging.info("Serving classic prompt selection page")
            prompt_files = list(PROMPTS_DIR.glob("*.md"))
            options = [file.name for file in prompt_files]
            return render_template("select_prompt.html", options=options)

        @self.app.route("/modern")
        def select_prompt_modern_route():
            logging.info("Serving modern prompt selection page (redirect)")
            prompt_files = list(PROMPTS_DIR.glob("*.md"))
            options = [file.name for file in prompt_files]
            return render_template("select_prompt_modern.html", options=options)

        @self.app.route("/run_agent", methods=["POST"])
        def run_agent_route():
            logging.info("Received request to run agent")
            try:
                choice = request.form.get("choice")
                filename = request.form.get("filename")
                prompt_text = request.form.get("prompt_text")
                logging.info(f"Form data: choice={choice}, filename={filename}, prompt_text length={len(prompt_text) if prompt_text else 0}")

                if choice == "new":
                    logging.info("Creating new prompt")
                    if not filename:
                        logging.error("Filename is required for new prompts")
                        return jsonify({"error": "Filename is required for new prompts"}), 400
                    new_prompt_path = PROMPTS_DIR / f"{filename}.md"
                    prompt_name = Path(filename).stem
                    with open(new_prompt_path, "w", encoding="utf-8") as f:
                        f.write(prompt_text or "")
                    task = prompt_text or ""
                else:
                    logging.info(f"Loading existing prompt: {choice}")
                    if not choice:
                        logging.error("Choice is required for existing prompts")
                        return jsonify({"error": "Choice is required for existing prompts"}), 400
                    prompt_path = PROMPTS_DIR / choice
                    if not prompt_path.exists():
                        logging.error(f"Prompt file not found: {prompt_path}")
                        return jsonify({"error": f"Prompt file not found: {choice}"}), 404
                    prompt_name = prompt_path.stem
                    if prompt_text:
                        logging.info("Updating existing prompt")
                        with open(prompt_path, "w", encoding="utf-8") as f:
                            f.write(prompt_text)
                    with open(prompt_path, "r", encoding="utf-8") as f:
                        task = f.read()
                    filename = prompt_path.stem

                # Configure repository directory for this prompt
                base_repo_dir = Path(get_constant("TOP_LEVEL_DIR")) / "repo"
                repo_dir = base_repo_dir / prompt_name
                repo_dir.mkdir(parents=True, exist_ok=True)
                set_prompt_name(prompt_name)
                set_constant("REPO_DIR", repo_dir)
                write_constants_to_file()
                
                logging.info(f"Starting agent runner in background thread for task: {prompt_name}")
                coro = self.agent_runner(task, self)
                self.socketio.start_background_task(asyncio.run, coro)
                return render_template("web_ide.html")
            except FileNotFoundError as e:
                logging.error(f"File not found in run_agent route: {e}", exc_info=True)
                return jsonify({"error": f"File not found: {str(e)}"}), 404
            except PermissionError as e:
                logging.error(f"Permission error in run_agent route: {e}", exc_info=True)
                return jsonify({"error": f"Permission error: {str(e)}"}), 403
            except Exception as e:
                logging.error(f"Unexpected error in run_agent route: {e}", exc_info=True)
                return jsonify({"error": f"Unexpected error starting agent: {str(e)}"}), 500

        @self.app.route("/messages")
        def get_messages():
            logging.info("Serving messages")
            return jsonify(
                {
                    "user": self.user_messages,
                    "assistant": self.assistant_messages,
                    "tool": self.tool_results,
                }
            )

        @self.app.route("/api/prompts/<path:filename>")
        def api_get_prompt(filename):
            """Return the raw content of a prompt file."""
            logging.info(f"Serving prompt content for: {filename}")
            try:
                prompt_path = PROMPTS_DIR / filename
                with open(prompt_path, "r", encoding="utf-8") as f:
                    data = f.read()
                return data, 200, {"Content-Type": "text/plain; charset=utf-8"}
            except FileNotFoundError:
                logging.error(f"Prompt not found: {filename}")
                return "Prompt not found", 404

        @self.app.route("/api/tasks")
        def api_get_tasks():
            """Return the list of available tasks."""
            logging.info("Serving tasks list")
            try:
                prompt_files = list(PROMPTS_DIR.glob("*.md"))
                tasks = [file.name for file in prompt_files]
                return jsonify(tasks)
            except Exception as e:
                logging.error(f"Error loading tasks: {e}")
                return jsonify([]), 500

        @self.app.route("/api/files")
        def api_get_files():
            """Return the file tree."""
            repo_dir = get_constant("REPO_DIR")
            if not repo_dir:
                return jsonify({"error": "REPO_DIR not configured"}), 500

            def get_file_tree(path):
                tree = []
                for item in sorted(Path(path).iterdir()):
                    node = {"name": item.name, "path": str(item.relative_to(repo_dir))}
                    if item.is_dir():
                        node["type"] = "directory"
                        node["children"] = get_file_tree(item)
                    else:
                        node["type"] = "file"
                    tree.append(node)
                return tree

        @self.app.route("/api/file_tree")
        def api_file_list():
            """Return a list of files under the current repository."""
            repo_dir = Path(get_constant("REPO_DIR"))
            files = [
                str(p.relative_to(repo_dir))
                for p in repo_dir.rglob("*")
                if p.is_file()
            ]
            return jsonify(files)

        @self.app.route("/api/file")
        def api_get_file():
            """Return the contents of a file within the repo."""
            rel_path = request.args.get("path", "")
            repo_dir = Path(get_constant("REPO_DIR"))
            safe_path = os.path.normpath(rel_path)
            
            try:
                file_path = repo_dir / safe_path
                if file_path.is_file():
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    return jsonify({"content": content})
                else:
                    return jsonify({"error": "File not found"}), 404
            except Exception as e:
                logging.error(f"Error getting file: {e}")
                return jsonify({"error": "Error getting file"}), 500

        @self.app.route("/api/files/content")
        def api_get_file_content():
            """Return the content of a file."""
            repo_dir = get_constant("REPO_DIR")
            if not repo_dir:
                return jsonify({"error": "REPO_DIR not configured"}), 500

            file_path = request.args.get("path")
            if not file_path:
                return jsonify({"error": "Missing path parameter"}), 400

            try:
                abs_path = Path(repo_dir) / file_path
                if not abs_path.is_file():
                    return jsonify({"error": "File not found"}), 404
                with open(abs_path, "r", encoding="utf-8") as f:
                    content = f.read()
                return jsonify({"content": content})
            except Exception as e:
                logging.error(f"Error getting file content: {e}")
                return jsonify({"error": "Error getting file content"}), 500


        @self.app.route("/tools")
        def tools_route():
            """Display available tools."""
            tool_list = []
            for tool in self.tool_collection.tools.values():
                info = tool.to_params()["function"]
                tool_list.append({"name": info["name"], "description": info["description"]})
            return render_template("tool_list.html", tools=tool_list)

        @self.app.route("/tools/<tool_name>", methods=["GET", "POST"])
        def run_tool_route(tool_name):
            """Run an individual tool from the toolbox."""
            tool = self.tool_collection.tools.get(tool_name)
            if not tool:
                return "Tool not found", 404
            params = tool.to_params()["function"]["parameters"]
            result_text = None
            if request.method == "POST":
                tool_input = {}
                for param in params.get("properties", {}):
                    value = request.form.get(param)
                    if value:
                        pinfo = params["properties"].get(param, {})
                        if pinfo.get("type") == "integer":
                            try:
                                tool_input[param] = int(value)
                            except ValueError:
                                tool_input[param] = value
                        elif pinfo.get("type") == "array":
                            try:
                                tool_input[param] = json.loads(value)
                            except Exception:
                                tool_input[param] = [v.strip() for v in value.split(',') if v.strip()]
                        else:
                            tool_input[param] = value
                try:
                    result = asyncio.run(self.tool_collection.run(tool_name, tool_input))
                    result_text = result.output or result.error
                except Exception as exc:
                    result_text = str(exc)
            return render_template(
                "tool_form.html",
                tool_name=tool_name,
                params=params,
                result=result_text,
            )

        @self.app.route("/browser")
        def file_browser_route():
            """Serve the VS Code-style file browser interface."""
            logging.info("Serving file browser interface")
            return render_template("file_browser.html")

        @self.app.route("/api/file-tree")
        def api_file_tree():
            """Return the file tree structure for the current REPO_DIR."""
            logging.info("Serving file tree")
            try:
                repo_dir = Path(get_constant("REPO_DIR"))
                if not repo_dir.exists():
                    return jsonify([])
                
                def build_tree(path):
                    items = []
                    try:
                        for item in sorted(path.iterdir()):
                            # Skip hidden files and directories
                            if item.name.startswith('.'):
                                continue
                            
                            if item.is_dir():
                                items.append({
                                    'name': item.name,
                                    'path': str(item),
                                    'type': 'directory',
                                    'children': build_tree(item)
                                })
                            else:
                                items.append({
                                    'name': item.name,
                                    'path': str(item),
                                    'type': 'file'
                                })
                    except PermissionError:
                        pass
                    return items
                
                tree = build_tree(repo_dir)
                return jsonify(tree)
            except Exception as e:
                logging.error(f"Error building file tree: {e}")
                return jsonify([])

        @self.app.route("/api/file-content")
        def api_file_content():
            """Return the content of a specific file."""
            file_path = request.args.get('path')
            if not file_path:
                return "File path is required", 400
            
            try:
                path = Path(file_path)
                # Security check - ensure the path is within REPO_DIR
                repo_dir = Path(get_constant("REPO_DIR"))
                if not path.resolve().is_relative_to(repo_dir.resolve()):
                    return "Access denied", 403
                
                if not path.exists():
                    return "File not found", 404
                
                if not path.is_file():
                    return "Path is not a file", 400
                
                # Try to read as text, handle binary files gracefully
                try:
                    with open(path, 'r', encoding='utf-8') as f:
                        content = f.read()
                except UnicodeDecodeError:
                    # If it's a binary file, return a message instead
                    return "Binary file - cannot display content", 200
                
                return content, 200, {"Content-Type": "text/plain; charset=utf-8"}
                
            except Exception as e:
                logging.error(f"Error reading file {file_path}: {e}")
                return f"Error reading file: {str(e)}", 500

        logging.info("Routes set up")

    def setup_socketio_events(self):
        logging.info("Setting up SocketIO events")

        @self.socketio.on("connect")
        def handle_connect():
            logging.info("Client connected")

        @self.socketio.on("disconnect")
        def handle_disconnect():
            logging.info("Client disconnected")

        @self.socketio.on("user_input")
        def handle_user_input(data):
            user_input = data.get("message", "") or data.get("input", "")
            logging.info(f"Received user input: {user_input}")
            # Queue is thread-safe; use blocking put to notify waiting tasks
            self.input_queue.put(user_input)

        @self.socketio.on("tool_response")
        def handle_tool_response(data):
            params = data.get("input", {}) if data.get("action") != "cancel" else {}
            logging.info(f"Received tool response: {data.get('action', 'execute')}")
            self.tool_queue.put(params)

        @self.socketio.on("interrupt_agent")
        def handle_interrupt_agent():
            logging.info("Received interrupt agent request")
            # This could be used to signal the agent to stop processing
            self.input_queue.put("INTERRUPT")
        logging.info("SocketIO events set up")

    def start_server(self, host="0.0.0.0", port=5002):
        logging.info(f"Starting server on {host}:{port}")
        self.socketio.run(self.app, host=host, port=port, use_reloader=False, allow_unsafe_werkzeug=True)

    def add_message(self, msg_type, content):
        logging.info(f"Adding message of type {msg_type}")
        log_message(msg_type, content)
        if msg_type == "user":
            self.user_messages.append(content)
            # Also emit to file browser
            self.socketio.emit("user_message", {"content": content})
        elif msg_type == "assistant":
            self.assistant_messages.append(content)
            # Also emit to file browser
            self.socketio.emit("assistant_message", {"content": content})
        elif msg_type == "tool":
            self.tool_results.append(content)
            # Parse tool result for file browser
            if isinstance(content, str):
                lines = content.split('\n')
                tool_name = "Unknown"
                if lines:
                    first_line = lines[0].strip()
                    if first_line.startswith('Tool:'):
                        tool_name = first_line.replace('Tool:', '').strip()
                self.socketio.emit("tool_result", {"tool_name": tool_name, "result": content})
                
                # Check if this tool might have created/modified files
                if any(keyword in content.lower() for keyword in ['created', 'wrote', 'generated', 'saved', 'modified', 'updated']):
                    # Emit file tree update after a short delay asynchronously
                    self.socketio.start_background_task(self._emit_file_tree_update)
                    
        self.broadcast_update()

    def broadcast_update(self):
        logging.info("Broadcasting update to clients")
        self.socketio.emit(
            "update",
            {
                "user": self.user_messages,
                "assistant": self.assistant_messages,
                "tool": self.tool_results,
            },
        )

    async def wait_for_user_input(self, prompt_message: str | None = None) -> str:
        """Await the next user input sent via the web UI input queue."""
        if prompt_message:
            logging.info(f"Emitting agent_prompt: {prompt_message}")
            self.socketio.emit("agent_prompt", {"message": prompt_message})

        loop = asyncio.get_running_loop()
        user_response = await loop.run_in_executor(None, self.input_queue.get)

        # Clear the prompt after input is received
        logging.info("Emitting agent_prompt_clear")
        self.socketio.emit("agent_prompt_clear")

        return user_response

    async def confirm_tool_call(self, tool_name: str, args: dict, schema: dict) -> dict | None:
        """Send a tool prompt to the web UI and wait for edited parameters."""
        self.socketio.emit(
            "tool_prompt",
            {"tool": tool_name, "values": args, "schema": schema},
        )
        loop = asyncio.get_running_loop()
        params = await loop.run_in_executor(None, self.tool_queue.get)
        self.socketio.emit("tool_prompt_clear")
        return params
</file>

</files>
